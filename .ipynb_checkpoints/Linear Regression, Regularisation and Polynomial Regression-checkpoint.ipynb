{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad0f4107-f6a7-49d4-a967-e981034d3910",
   "metadata": {},
   "source": [
    "# Linear Regression, Regularisation and Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee517fa-4b49-4110-bf50-ed3d055e99a3",
   "metadata": {},
   "source": [
    "### Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6d3f7c82-46af-4c27-bcfd-ed98af87d81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_model(y_true, y_pred, X_test):\n",
    "    n = X_test.shape[0]  # number of samples\n",
    "    p = X_test.shape[1]  # number of predictors\n",
    "\n",
    "    # Since we logged the resale prices during data processing, we exponetiate it back to view the metrics in dollars and not log units\n",
    "    y_true = np.exp(y_true)\n",
    "    y_pred = np.exp(y_pred)\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    adj_r2 = 1 - ((1 - r2) * (n - 1) / (n - p - 1))\n",
    "\n",
    "    metrics = pd.Series({\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'R^2': r2,\n",
    "        'Adjusted R²': adj_r2\n",
    "    })\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae754f0-9990-43c1-b649-03203826130c",
   "metadata": {},
   "source": [
    "### Linear Regression Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "df02e51a-e813-4067-8dd6-156d10e1038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "def linear_regression_eval(X_train, X_test, y_train, y_test):\n",
    "    # Initialize model\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # Fit on training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate model performance\n",
    "    metrics = evaluate_model(y_test, y_pred, X_test)\n",
    "    print(\"Linear Regression Performance:\")\n",
    "    print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c0e70d-b9fe-4dbe-a4c5-4e16ed70de3e",
   "metadata": {},
   "source": [
    "### Lasso Regression Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "52b51922-0ff0-43ab-ac4b-28f2f76ac0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "\n",
    "def lasso_regression_eval(X_train, X_test, y_train, y_test, cv=10, random_state=42):\n",
    "    # Create pipeline with scaling and LassoCV\n",
    "    model = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        LassoCV(cv=cv, random_state=random_state)\n",
    "    )\n",
    "    \n",
    "    # Fit on training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Get best alpha from the LassoCV step\n",
    "    best_alpha = model.named_steps['lassocv'].alpha_\n",
    "    \n",
    "    # Evaluate model performance (assuming evaluate_model is defined)\n",
    "    metrics = evaluate_model(y_test, y_pred, X_test)\n",
    "    \n",
    "    # Print best alpha and evaluation metrics\n",
    "    print(f\"Best alpha: {best_alpha}\")\n",
    "    print(\"Lasso Regression Performance:\")\n",
    "    print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c68842-5ed6-4230-bdc5-1fd33dcca18c",
   "metadata": {},
   "source": [
    "### Ridge Regression Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0e95f139-b64b-431f-ba56-cae860b9b312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "\n",
    "def ridge_regression_eval(X_train, X_test, y_train, y_test, alphas=None, cv=10):\n",
    "    # Default alphas if not provided\n",
    "    if alphas is None:\n",
    "        alphas = np.logspace(-6, 6, 13)\n",
    "    \n",
    "    # Create pipeline with scaling and RidgeCV\n",
    "    model = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        RidgeCV(alphas=alphas, cv=cv)\n",
    "    )\n",
    "    \n",
    "    # Fit on training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Get best alpha from RidgeCV step\n",
    "    best_alpha = model.named_steps['ridgecv'].alpha_\n",
    "    \n",
    "    # Evaluate model performance (assuming evaluate_model is defined)\n",
    "    metrics = evaluate_model(y_test, y_pred, X_test)\n",
    "    \n",
    "    # Print best alpha and evaluation metrics\n",
    "    print(f\"Best alpha: {best_alpha}\")\n",
    "    print(\"Ridge Regression Performance:\")\n",
    "    print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2399458-5635-4359-b271-6fa78729e767",
   "metadata": {},
   "source": [
    "### Polynomial Regression Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6164fbd3-924f-4a23-a007-01f6500f2174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def polynomial_regression_eval(X_train, X_test, y_train, y_test, degree=2):\n",
    "    # Create pipeline with polynomial features and linear regression\n",
    "    model = make_pipeline(\n",
    "        PolynomialFeatures(degree=degree, include_bias=False),\n",
    "        LinearRegression()\n",
    "    )\n",
    "    \n",
    "    # Fit on training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate model performance (assuming evaluate_model is defined)\n",
    "    metrics = evaluate_model(y_test, y_pred, X_test)\n",
    "    \n",
    "    # Print evaluation metrics\n",
    "    print(f\"Polynomial Regression Performance (degree={degree}):\")\n",
    "    print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7399f134-f191-4f5d-835f-3481d9fa17cb",
   "metadata": {},
   "source": [
    "## df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c6714277-6812-4104-8802-bdead0c6b60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_base_train = pd.read_pickle(\"X_base_train.pkl\")\n",
    "X_base_test = pd.read_pickle(\"X_base_test.pkl\")\n",
    "y_base_train = pd.read_pickle(\"y_base_train.pkl\")\n",
    "y_base_test = pd.read_pickle(\"y_base_test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64ae804-16e0-4e43-bf3a-3571deb9c45d",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8844af83-fc1a-418f-946e-a9a59f64ca4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MAE            1.278118e+05\n",
       "MSE            2.192958e+10\n",
       "RMSE           1.480864e+05\n",
       "R^2            3.834172e-01\n",
       "Adjusted R²    3.828996e-01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression_eval(X_base_train, X_base_test, y_base_train, y_base_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef9639f-7623-444f-9530-656c76638a34",
   "metadata": {},
   "source": [
    "### Lasso (L1 Regularisation)\n",
    "\n",
    "LassoCV automatically generates 100 default alpha values (the hyperparameter controlling the regularization strength) based on the data. It then applies cross-validation to select the alpha that minimizes the training mean squared error (MSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2e9b23ec-d6c7-4763-a557-7794e726f972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.00021601217412189918\n",
      "Lasso Regression Performance:\n",
      "MAE            1.281465e+05\n",
      "MSE            2.206658e+10\n",
      "RMSE           1.485482e+05\n",
      "R^2            3.795652e-01\n",
      "Adjusted R²    3.790444e-01\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "lasso_regression_eval(X_base_train, X_base_test, y_base_train, y_base_test, cv=10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81f1ba3-6a32-442e-8e63-11500cdbfc3c",
   "metadata": {},
   "source": [
    "### Ridge (L2 Regularisation)\n",
    "In contrast, RidgeCV does not automatically determine alpha values from the data. Instead, it defaults to a fixed set of alphas such as [0.1, 1.0, 10.0]. To achieve better model tuning, we specify a custom range of alpha values. Like LassoCV, RidgeCV uses cross-validation to select the alpha that results in the lowest training MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9dfbd897-6d6a-4a28-93d8-2232df0eb3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 1000.0\n",
      "Ridge Regression Performance:\n",
      "MAE            1.281840e+05\n",
      "MSE            2.208519e+10\n",
      "RMSE           1.486109e+05\n",
      "R^2            3.790420e-01\n",
      "Adjusted R²    3.785207e-01\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ridge_regression_eval(X_base_train, X_base_test, y_base_train, y_base_test, alphas=None, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366ad9f4-ae6b-42ae-8289-11d2209c455a",
   "metadata": {},
   "source": [
    "### Polynomial Regression Degree=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "22f2e1b9-0659-41d3-93ac-fe801bc1bd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Regression Performance (degree=2):\n",
      "MAE            4.549957e+04\n",
      "MSE            4.329693e+09\n",
      "RMSE           6.580040e+04\n",
      "R^2            8.782643e-01\n",
      "Adjusted R²    8.781621e-01\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "polynomial_regression_eval(X_base_train, X_base_test, y_base_train, y_base_test, degree=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049f13ee-5134-4637-a54c-932a2d857554",
   "metadata": {},
   "source": [
    "## df_post_covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b89e3f4f-deef-4c9d-9dfe-164c89dbd142",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_post_train = pd.read_pickle(\"X_post_train.pkl\")\n",
    "X_post_test = pd.read_pickle(\"X_post_test.pkl\")\n",
    "y_post_train = pd.read_pickle(\"y_post_train.pkl\")\n",
    "y_post_test = pd.read_pickle(\"y_post_test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7713e02e-869f-489b-87e5-86c3c319d353",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6d2cc832-3442-436a-a240-103647b76e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Performance:\n",
      "MAE            4.716768e+04\n",
      "MSE            3.897595e+09\n",
      "RMSE           6.243072e+04\n",
      "R^2            8.993742e-01\n",
      "Adjusted R²    8.991935e-01\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "linear_regression_eval(X_post_train, X_post_test, y_post_train, y_post_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5892aa58-48e6-4e17-bd35-ac592be8e274",
   "metadata": {},
   "source": [
    "### Lasso (L1 Regularisation)\n",
    "\n",
    "LassoCV automatically generates 100 default alpha values (the hyperparameter controlling the regularization strength) based on the data. It then applies cross-validation to select the alpha that minimizes the training mean squared error (MSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "57f47c9f-4325-45d0-8238-c6a7a15b269f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.00021873592047883046\n",
      "Lasso Regression Performance:\n",
      "MAE            4.704637e+04\n",
      "MSE            3.885107e+09\n",
      "RMSE           6.233063e+04\n",
      "R^2            8.996966e-01\n",
      "Adjusted R²    8.995164e-01\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "lasso_regression_eval(X_post_train, X_post_test, y_post_train, y_post_test, cv=10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a595037-ee7a-4674-9f64-1b5899257a3a",
   "metadata": {},
   "source": [
    "### Ridge (L2 Regularisation)\n",
    "In contrast, RidgeCV does not automatically determine alpha values from the data. Instead, it defaults to a fixed set of alphas such as [0.1, 1.0, 10.0]. To achieve better model tuning, we specify a custom range of alpha values. Like LassoCV, RidgeCV uses cross-validation to select the alpha that results in the lowest training MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9505d346-8116-4a22-9dea-4ba73fefd8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 100.0\n",
      "Ridge Regression Performance:\n",
      "MAE            4.710623e+04\n",
      "MSE            3.890184e+09\n",
      "RMSE           6.237134e+04\n",
      "R^2            8.995655e-01\n",
      "Adjusted R²    8.993851e-01\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ridge_regression_eval(X_post_train, X_post_test, y_post_train, y_post_test, alphas=None, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4b42c2-13a3-44ae-a352-3094a22324bf",
   "metadata": {},
   "source": [
    "### Polynomial Regresison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4c88ebe8-1918-46fe-9161-2482dcf8824f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Regression Performance (degree=2):\n",
      "MAE            4.390866e+04\n",
      "MSE            3.914648e+09\n",
      "RMSE           6.256715e+04\n",
      "R^2            8.989339e-01\n",
      "Adjusted R²    8.987524e-01\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "polynomial_regression_eval(X_post_train, X_post_test, y_post_train, y_post_test, degree=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
